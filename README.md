# Summmary
记录我的进度
---
description: 记录我的工作进度，不要摸鱼，加油前进！
---


# 😀 Overview

### BasicNet

* [X] [ResNet 残差网络](/BasicNet/ResNet/ResNet.md)**[[Paper](https://arxiv.org/abs/1512.03385)]** 


* [ ] [denseNet 稠密连接网络](/BasicNet/denseNet/denseNet.md)**[[Paper](https://arxiv.org/abs/1608.06993)]** 

### Backbone

* [ ] [Attention Is All You Need] (_NeurIPS '17_) **[[Paper](https://proceedings.neurips.cc/paper/7181-attention-is-all)]** **[[Code_official](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py)]** **[[Code_community](https://github.com/jadore801120/attention-is-all-you-need-pytorch)]**
* [ ] [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks] (_ICML '19_) **[[Paper](https://arxiv.org/abs/1905.11946)]** **[[Code](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)]**
* [ ] [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale] (_ICLR '21_) **[[Paper](https://arxiv.org/abs/2010.11929)]** **[[Code](https://github.com/google-research/vision_transformer)]**
* [ ] [Multi-Dimensional Model Compression of Vision Transformer] (_ICME '22_) **[[Paper](https://arxiv.org/abs/2201.00043)]**
* [ ] Deep Residual Learning for Image Recognition (_CVPR '16_) **[[Paper](https://arxiv.org/abs/1512.03385)]**
* [ ] Generative Adversarial Networks (_NeurIPS '14_) **[[Paper](https://papers.nips.cc/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html)]**
* [ ] Masked Auto-Encoders Meet Generative Adversarial Networks and Beyond (_CVPR '23_) **[[Paper](https://feizc.github.io/resume/ganmae.pdf)]**
* [ ] A Kernel Perspective of Skip Connections in Convolutional Networks (_ICLR '23_) **[[Paper](https://arxiv.org/abs/2211.14810)]**
* [ ] EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention (_CVPR '23_) **[[Paper](https://arxiv.org/abs/2305.07027)]** **[[Code](https://github.com/microsoft/Cream/tree/main/EfficientViT)]** **[[Note_community](https://blog.csdn.net/P_LarT/article/details/130687567)]**




